# 1. FIFO 

	FIFO 认为，最早添加的记录，其不再被使用的可能性比刚添加的可能性大。

# 2. LFU (Least Frequently Used)

	LFU 认为，如果数据过去被访问多次，那么将来被访问的频率也更高。

淘汰缓存中访问频率最低的记录。

LFU 算法的命中率是比较高的，但缺点也非常明显，维护每个记录的访问次数，
- 对*内存的消耗是很高*的；
- 如果数据的访问模式发生变化，LFU 需要较长的时间去适应，也就是说 LFU 算法受历史数据的影响比较大。


# 3. LRU(Least Recently Used)

	LRU 认为，如果数据最近被访问过，那么将来被访问的概率也会更高。

相对于仅考虑时间因素的 FIFO 和仅考虑访问频率的 LFU，LRU 算法可以认为是相对平衡的一种淘汰算法

![[Pasted image 20210828141958.png]]

-   绿色的是字典(map)，存储键和值的映射关系。这样根据某个键(key)查找对应的值(value)的复杂是`O(1)`，在字典中插入一条记录的复杂度也是`O(1)`。
-   红色的是双向链表(double linked list)实现的队列。将所有的值放到双向链表中，这样，当访问到某个值时，将其移动到队尾的复杂度是`O(1)`，在队尾新增一条记录以及删除一条记录的复杂度均为`O(1)`。


# LRU-k

Problem of LRU:

> LRU is unable to differentiate between pages that have relatively frequent reference and pages that have very infrequent reference.

The backward-k distance:

$$
	b_t(p, K) = \begin{cases}
		x  &\quad r_{t-x} = p \and x \le k \\
		\infty &\quad \textrm{otherwise}
	\end{cases}
$$

The LRU-K Algorithm specifies a page replacement policy when a buffer slot is needed for a new page being read in from disk the page $p$ to be dropped (i.e., selected as a replacement victim) is the one whose Backward K-distance, $b_t(p, K)$, is the maximum of all pages in buffer. 

a subsidiary policy maybe used to select a replacement victim among the pages with infinite Backward K-distance; for example, classical LRU could be employed as a subsidiary policy. 

![[Pasted image 20210828153331.png]]


> 缓存雪崩：缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。常因为缓存服务器宕机，或缓存设置了相同的过期时间引起。

#  一致性哈希


一致性哈希算法将 key 映射到 2^32 的空间中，将这个数字首尾相连，形成一个环。

-   计算节点/机器(通常使用节点的名称、编号和 IP 地址)的哈希值，放置在环上。
-   计算 key 的哈希值，放置在环上，顺时针寻找到的第一个节点，就是应选取的节点/机器。

![[Pasted image 20210828154440.png]]

> 一致性哈希算法，在新增/删除节点时，只需要重新定位该节点附近的一小部分数据，而不需要重新定位所有的节点，这就解决了上述的问题。

如果服务器的节点过少，容易引起 key 的倾斜。例如上面例子中的 peer2，peer4，peer6 分布在环的上半部分，下半部分是空的。那么映射到环下半部分的 key 都会被分配给 peer2，key 过度向 peer2 倾斜，缓存节点间负载不均。

为了解决这个问题，引入了虚拟节点的概念，一个真实节点对应多个虚拟节点。


## single flight

singleflight这样理解对不对：  
在一瞬间有大量请求get(key)，而且key未被缓存或者未被缓存在当前节点 如果不用singleflight，那么这些请求都会发送远端节点或者从本地数据库读取，会造成远端节点或本地数据库压力猛增。使用singleflight，第一个get(key)请求到来时，singleflight会记录当前key正在被处理，后续的请求只需要等待第一个请求处理完成，取返回值即可。